{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "57e2bf2b",
      "metadata": {
        "id": "57e2bf2b"
      },
      "source": [
        "# 1 Checking the TF version and availability of physical devices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca84fe5",
      "metadata": {
        "id": "dca84fe5"
      },
      "source": [
        "#### a Get the version of TensorFlow running on your machine? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97f594b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97f594b",
        "outputId": "db6e814f-11d0-45e0-de32-e6618e3a4a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc89cf98",
      "metadata": {
        "id": "cc89cf98"
      },
      "source": [
        "### b. To get the type and number of physical devices available on your machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89249704",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89249704",
        "outputId": "ca17ef69-0a16-4717-a2fd-2b52d29a0089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices available:  1\n",
            "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
            "GPU is not available\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "devices = tf.config.list_physical_devices()\n",
        "\n",
        "\n",
        "    \n",
        "print(\"Number of devices available: \", len(devices))\n",
        "for device in devices:\n",
        "    print(device)\n",
        "    if \"GPU\" in device.device_type:\n",
        "        print(\"GPU is available\")\n",
        "    else:\n",
        "        print(\"GPU is not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642945b0",
      "metadata": {
        "id": "642945b0"
      },
      "source": [
        "# 2. Random number generator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f78ff0c1",
      "metadata": {
        "id": "f78ff0c1"
      },
      "source": [
        "### a. What is the need for setting a 'seed' value in any random number generation?\n",
        "Setting a 'seed' value in any random number generation is important for reproducibility. When we generate random numbers, the values produced are not truly random but are based on some algorithmic calculations. Therefore, if we set the same seed value, we can ensure that the random numbers generated are the same every time we run the code, making the results reproducible. This is particularly useful in scientific research and machine learning, where the ability to reproduce results is crucial."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "727cee31",
      "metadata": {
        "id": "727cee31"
      },
      "source": [
        "### b. Create two random number generators using TensorFlow with the same seed of 42, create two random gaussian tensors of shape 2x3, and verify that the both tensors are identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a203dde8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a203dde8",
        "outputId": "0ddf0459-ed96-4c6a-eb3e-5836f1d69925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.3274685 -0.8426258  0.3194337]\n",
            " [-1.4075519 -2.3880599 -1.0392479]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[False False False]\n",
            " [False False False]], shape=(2, 3), dtype=bool)\n",
            "Are the two tensors identical?  tf.Tensor(False, shape=(), dtype=bool)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create two random Gaussian tensors of shape 2x3\n",
        "tensor1 = tf.random.normal(shape=(2, 3))\n",
        "tensor2 = tf.random.normal(shape=(2, 3))\n",
        "\n",
        "# Verify that both tensors are identical\n",
        "print(\"Are the two tensors identical? \", tf.reduce_all(tensor1 == tensor2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8900250",
      "metadata": {
        "id": "f8900250"
      },
      "source": [
        "### c. Create two random number generators using TensorFlow with two different seed values say 42 & 11, create two random gaussian tensors of shape 2x3, and verify that the both tensors are not identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ddcc99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ddcc99",
        "outputId": "6b6a61ee-cafd-40b7-a0fd-f47a86a9f7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are the two tensors identical?  tf.Tensor(False, shape=(), dtype=bool)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create first random Gaussian tensor of shape 2x3\n",
        "tensor1 = tf.random.normal(shape=(2, 3))\n",
        "\n",
        "tf.random.set_seed(11)\n",
        "\n",
        "# Create second random Gaussian tensor of shape 2x3\n",
        "tensor2 = tf.random.normal(shape=(2, 3))\n",
        "\n",
        "# Verify that both tensors are not identical\n",
        "print(\"Are the two tensors identical? \", tf.reduce_all(tensor1 == tensor2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b31641a",
      "metadata": {
        "id": "6b31641a"
      },
      "source": [
        "# 3. Shuffling of Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8555f5df",
      "metadata": {
        "id": "8555f5df"
      },
      "source": [
        "### a. Shuffle the given Tensor with and without an operation seed value. Write down your observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889c64a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "889c64a4",
        "outputId": "d3bb3763-0962-4d5b-fb4b-a455f06b2e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffled tensor without seed:\n",
            " [[1 2]\n",
            " [7 8]\n",
            " [5 6]\n",
            " [3 4]]\n"
          ]
        }
      ],
      "source": [
        "#Without seed:\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the input tensor\n",
        "input_tensor = tf.constant([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "\n",
        "# Shuffle the input tensor without seed\n",
        "shuffled_tensor = tf.random.shuffle(input_tensor)\n",
        "\n",
        "# Print the shuffled tensor\n",
        "print(\"Shuffled tensor without seed:\\n\", shuffled_tensor.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d787764d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d787764d",
        "outputId": "a394b722-db63-4f82-8edb-1eb03cf5e73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffled tensor with seed:\n",
            " [[7 8]\n",
            " [1 2]\n",
            " [3 4]\n",
            " [5 6]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#with seed\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the input tensor\n",
        "input_tensor = tf.constant([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "\n",
        "# Shuffle the input tensor with seed\n",
        "tf.random.set_seed(42)\n",
        "shuffled_tensor = tf.random.shuffle(input_tensor)\n",
        "\n",
        "# Print the shuffled tensor\n",
        "print(\"Shuffled tensor with seed:\\n\", shuffled_tensor.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5937570f",
      "metadata": {
        "id": "5937570f"
      },
      "source": [
        "#### Observations:\n",
        "When shuffling a Tensor without a seed value, the order of elements in the resulting shuffled Tensor will be different each time the operation is executed.\n",
        "When shuffling a Tensor with a seed value, the order of elements in the resulting shuffled Tensor will be the same every time the operation is executed, as long as the seed value remains the same.\n",
        "If the same seed value is used for multiple shuffling operations, the order of elements in the shuffled Tensors will be the same."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b4f584",
      "metadata": {
        "id": "52b4f584"
      },
      "source": [
        "### b. Show that 'operation seed' in 'tf.random.shuffle' and the 'global seed' in 'tf.random.set_seed' are different? Illustrate that having both gives the tensor in same order every time after shuffling?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04266c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04266c8",
        "outputId": "64355acb-2431-4373-ddbe-6c375f2f58a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffled tensor with operation seed:\n",
            " [[3 4]\n",
            " [1 2]\n",
            " [7 8]\n",
            " [5 6]]\n",
            "Shuffled tensor with global seed:\n",
            " [[7 8]\n",
            " [1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "Shuffled tensor with global seed (second execution):\n",
            " [[7 8]\n",
            " [1 2]\n",
            " [3 4]\n",
            " [5 6]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the input tensor\n",
        "input_tensor = tf.constant([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "\n",
        "# Shuffle the input tensor with operation seed\n",
        "tf.random.set_seed(42)\n",
        "shuffled_tensor_op_seed = tf.random.shuffle(input_tensor, seed=11)\n",
        "\n",
        "# Shuffle the input tensor with global seed\n",
        "tf.random.set_seed(42)\n",
        "shuffled_tensor_global_seed = tf.random.shuffle(input_tensor)\n",
        "tf.random.set_seed(42)\n",
        "shuffled_tensor_global_seed2 = tf.random.shuffle(input_tensor)\n",
        "\n",
        "# Print the shuffled tensors\n",
        "print(\"Shuffled tensor with operation seed:\\n\", shuffled_tensor_op_seed.numpy())\n",
        "print(\"Shuffled tensor with global seed:\\n\", shuffled_tensor_global_seed.numpy())\n",
        "print(\"Shuffled tensor with global seed (second execution):\\n\", shuffled_tensor_global_seed2.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bbe2040",
      "metadata": {
        "id": "7bbe2040"
      },
      "source": [
        "#### Observations:\n",
        "This code will shuffle the input tensor with both an operation seed and a global seed. We can observe the following:\n",
        "\n",
        "The shuffled tensor with operation seed is different from the shuffled tensor with global seed.\n",
        "When we execute the same shuffling operation with the same global seed multiple times, we get the same shuffled tensor every time.\n",
        "When we execute the same shuffling operation with different global seed values, we get different shuffled tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1701f9fa",
      "metadata": {
        "id": "1701f9fa"
      },
      "source": [
        "# 4. Reshaping the tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c220bd",
      "metadata": {
        "id": "56c220bd"
      },
      "source": [
        "#### a. (i) Construct a vector consisting of first 24 integers using 'numpy'\n",
        "####     (ii) Convert that ‘numpy’ vector into a Tensor of rank 3.\n",
        "####     (iii) Write your observations on how the elements of the vector got rearranged in the rank 3 tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686ba3c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "686ba3c2",
        "outputId": "ea094610-0cb2-4685-a40a-2b9b8b145a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped Tensor (Rank 3):\n",
            " [[[ 1  2  3  4]\n",
            "  [ 5  6  7  8]\n",
            "  [ 9 10 11 12]]\n",
            "\n",
            " [[13 14 15 16]\n",
            "  [17 18 19 20]\n",
            "  [21 22 23 24]]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Construct a vector of first 24 integers using NumPy\n",
        "vector = np.arange(1, 25)\n",
        "\n",
        "# Convert the NumPy vector to a Tensor of rank 3\n",
        "tensor_rank3 = tf.reshape(vector, shape=(2, 3, 4))\n",
        "\n",
        "# Print the reshaped tensor\n",
        "print(\"Reshaped Tensor (Rank 3):\\n\", tensor_rank3.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba3aa55",
      "metadata": {
        "id": "5ba3aa55"
      },
      "source": [
        "###### Observations:\n",
        "\n",
        "The elements of the vector got rearranged in the rank 3 Tensor in a row-major order, i.e., from left to right, top to bottom, and front to back.\n",
        "In this specific case, the first 4 integers (1 to 4) became the first row of the first matrix, the next 4 integers (5 to 8) became the second row of the first matrix, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77cecda",
      "metadata": {
        "id": "b77cecda"
      },
      "source": [
        "#### b. (i) Create a tensor of rank 2.\n",
        "####     (ii) Convert that tensor into another tensor of shape 2x2x1 using 'tf.newaxis'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52f2b58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d52f2b58",
        "outputId": "d881932e-1815-4492-cf3d-8db1122d6338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor (Rank 2):\n",
            " [[1 2]\n",
            " [3 4]]\n",
            "Tensor (Rank 3) with newaxis:\n",
            " [[[1]\n",
            "  [2]]\n",
            "\n",
            " [[3]\n",
            "  [4]]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a Tensor of rank 2\n",
        "tensor_rank2 = tf.constant([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert the Tensor of rank 2 to another Tensor of shape 2x2x1 using tf.newaxis\n",
        "tensor_rank3_newaxis = tensor_rank2[:, :, tf.newaxis]\n",
        "\n",
        "# Print both tensors\n",
        "print(\"Tensor (Rank 2):\\n\", tensor_rank2.numpy())\n",
        "print(\"Tensor (Rank 3) with newaxis:\\n\", tensor_rank3_newaxis.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d74eff8",
      "metadata": {
        "id": "5d74eff8"
      },
      "source": [
        "#### c. (i) Create a tensor of rank 2.\n",
        "####     (ii) Convert that tensor into another tensor of shape 2x2x1 using 'tf.expand_dims'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976a1ae1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "976a1ae1",
        "outputId": "32f9492f-c85c-4b50-c8dd-b74f7f0c2db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor (Rank 2):\n",
            " [[1 2]\n",
            " [3 4]]\n",
            "Tensor (Rank 3) with expand_dims:\n",
            " [[[1]\n",
            "  [2]]\n",
            "\n",
            " [[3]\n",
            "  [4]]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a Tensor of rank 2\n",
        "tensor_rank2 = tf.constant([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert the Tensor of rank 2 to another Tensor of shape 2x2x1 using tf.expand_dims\n",
        "tensor_rank3_expand_dims = tf.expand_dims(tensor_rank2, axis=-1)\n",
        "\n",
        "# Print both tensors\n",
        "print(\"Tensor (Rank 2):\\n\", tensor_rank2.numpy())\n",
        "print(\"Tensor (Rank 3) with expand_dims:\\n\", tensor_rank3_expand_dims.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4317af4b",
      "metadata": {
        "id": "4317af4b"
      },
      "source": [
        "# 5. Linear Regression full experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161a3240",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "161a3240",
        "outputId": "807a54c4-48db-4afd-c8c1-36f29352fda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "400/400 [==============================] - 2s 2ms/step - loss: 175442208.0000\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 100267760.0000\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 29256264.0000\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 4048688.2500\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 1011541.5625\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 903849.2500\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 899595.8125\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 895982.6250\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 891013.6250\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 885587.3125\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "Mean squared error: 916920.3181620206\n",
            "R2 score: 0.1406382908093161\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Housing_data.csv')\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# create the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# train the MLP model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=10)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluate the performance of the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('Mean squared error:', mse)\n",
        "print('R2 score:', r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9abb37b",
      "metadata": {
        "id": "d9abb37b"
      },
      "source": [
        "# 6. Regularization full experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff9f08c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ff9f08c",
        "outputId": "8829c2b6-655a-4a36-b708-9deed8a99146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge regression:\n",
            "Train MSE: 0.52\n",
            "Test MSE: 0.56\n",
            "Lasso regression:\n",
            "Train MSE: 1.34\n",
            "Test MSE: 1.31\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Perform Ridge regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "ridge_train_predictions = ridge.predict(X_train_scaled)\n",
        "ridge_test_predictions = ridge.predict(X_test_scaled)\n",
        "ridge_train_mse = mean_squared_error(y_train, ridge_train_predictions)\n",
        "ridge_test_mse = mean_squared_error(y_test, ridge_test_predictions)\n",
        "print(\"Ridge regression:\")\n",
        "print(f\"Train MSE: {ridge_train_mse:.2f}\")\n",
        "print(f\"Test MSE: {ridge_test_mse:.2f}\")\n",
        "\n",
        "# Perform Lasso regression\n",
        "lasso = Lasso(alpha=1.0)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "lasso_train_predictions = lasso.predict(X_train_scaled)\n",
        "lasso_test_predictions = lasso.predict(X_test_scaled)\n",
        "lasso_train_mse = mean_squared_error(y_train, lasso_train_predictions)\n",
        "lasso_test_mse = mean_squared_error(y_test, lasso_test_predictions)\n",
        "print(\"Lasso regression:\")\n",
        "print(f\"Train MSE: {lasso_train_mse:.2f}\")\n",
        "print(f\"Test MSE: {lasso_test_mse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "413ccc0a",
      "metadata": {
        "id": "413ccc0a"
      },
      "source": [
        "# 9. Write a Program for text processing to identify the POS tags from the input text?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707e7413",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "707e7413",
        "outputId": "8efb1808-cbde-4ba8-cae2-92f3d61d7b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "quick ADJ\n",
            "brown ADJ\n",
            "fox NOUN\n",
            "jumps VERB\n",
            "over ADP\n",
            "the DET\n",
            "lazy ADJ\n",
            "dog NOUN\n",
            ". PUNCT\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Input text\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Process the text with the language model\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the POS tags for each token\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9192c080",
      "metadata": {
        "id": "9192c080"
      },
      "source": [
        "# 10. Write a Program for Text Processing to identify the common tags for the parsing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ece314",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ece314",
        "outputId": "3a8782c1-a3e5-44cf-f9ba-1eb398a657c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most common tags:\n",
            "JJ: 3\n",
            "DT: 2\n",
            "NN: 2\n",
            "VBZ: 1\n",
            "IN: 1\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define input text\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Process the text with the language model\n",
        "doc = nlp(text)\n",
        "\n",
        "# Get the tags for each token\n",
        "tags = [token.tag_ for token in doc]\n",
        "\n",
        "# Count the occurrence of each tag\n",
        "tag_counts = {}\n",
        "for tag in tags:\n",
        "    if tag in tag_counts:\n",
        "        tag_counts[tag] += 1\n",
        "    else:\n",
        "        tag_counts[tag] = 1\n",
        "\n",
        "# Sort the tags by frequency\n",
        "sorted_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the top 5 most common tags\n",
        "print(\"Top 5 most common tags:\")\n",
        "for tag, count in sorted_tags[:5]:\n",
        "    print(f\"{tag}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba23ee44",
      "metadata": {
        "id": "ba23ee44"
      },
      "source": [
        "# 11. Write a program for Text Processing to identify the Named Entity Recognition from the given Text? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5330d3c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5330d3c0",
        "outputId": "936eeb10-28f3-477b-9166-52122ca96442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b36ed7f",
      "metadata": {
        "id": "0b36ed7f"
      },
      "source": [
        "# 12. Write the Code for implementing the LSTM model for the sentiment Analysis on IMDB Movie Reviews dataset with Sigmoid Optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80485d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f80485d7",
        "outputId": "a7723625-88ab-45f8-99ba-55b13d64b0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 1337s 2s/step - loss: 0.4636 - accuracy: 0.7798 - val_loss: 0.3309 - val_accuracy: 0.8636\n",
            "782/782 [==============================] - 153s 196ms/step - loss: 0.3309 - accuracy: 0.8636\n",
            "Test score: 0.3308878540992737\n",
            "Test accuracy: 0.8636000156402588\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "# Set the maximum number of words to consider in the dataset\n",
        "max_features = 5000\n",
        "\n",
        "# Load the IMDB Movie Reviews dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Set the maximum length of a review (in words)\n",
        "maxlen = 500\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with the sigmoid optimizer\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=1, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc5a83d",
      "metadata": {
        "id": "2fc5a83d"
      },
      "source": [
        "# 13. Write the Code for implementing the LSTM model for the sentiment Analysis on IMDB Movie Reviews dataset with Adam Optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b86ab03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b86ab03",
        "outputId": "83ec3af1-df58-459b-bebc-0452552fa216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 216s 532ms/step - loss: 0.5765 - accuracy: 0.6919 - val_loss: 0.4363 - val_accuracy: 0.8089\n",
            "Accuracy: 80.89%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# load the IMDB dataset\n",
        "max_features = 5000\n",
        "maxlen = 100\n",
        "batch_size = 64\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "# create the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
        "\n",
        "# train the LSTM model\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=1, validation_data=(X_test, y_test))\n",
        "\n",
        "# evaluate the performance of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "246022cc",
      "metadata": {
        "id": "246022cc"
      },
      "source": [
        "# 14. Write the Code for implementing the LSTM model for the sentiment Analysis on IMDB Movie Reviews dataset with ‘RMSProp’ Optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d212e7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d212e7d",
        "outputId": "f05ed749-b0ac-4871-9dc7-922b0636a435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 16s 81ms/step - loss: 0.4890 - acc: 0.7664 - val_loss: 0.3665 - val_acc: 0.8358\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3706 - acc: 0.8359\n",
            "Test accuracy: 0.835919976234436\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils import pad_sequences\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Preprocess the data\n",
        "max_len = 100\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=1, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "87d07830019094722aa2be3e0c92e49496384d6634002424d48a8c53637ec064"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}