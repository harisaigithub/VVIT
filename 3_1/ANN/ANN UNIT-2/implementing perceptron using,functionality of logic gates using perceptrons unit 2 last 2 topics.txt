1. Implementing Functionality of Logic Gates Using Perceptron in Python:

You can implement the functionality of logic gates (AND, OR, NOT, XOR, etc.) using perceptrons in Python. Below is the Python code that demonstrates this


import numpy as np

class Perceptron:
    def __init__(self, num_inputs, learning_rate=0.1):
        # Initialize weights and bias
        self.weights = np.random.rand(num_inputs)
        self.bias = np.random.rand()
        self.learning_rate = learning_rate

    def predict(self, inputs):
        # Calculate the weighted sum of inputs
        weighted_sum = np.dot(inputs, self.weights) + self.bias
        # Apply the activation function (Step function)
        return 1 if weighted_sum > 0 else 0

    def train(self, training_data, labels, epochs):
        for _ in range(epochs):
            for inputs, label in zip(training_data, labels):
                prediction = self.predict(inputs)
                error = label - prediction
                # Update weights and bias
                self.weights += self.learning_rate * error * inputs
                self.bias += self.learning_rate * error

# Example usage for AND, OR, NOT, and XOR gates
if __name__ == "__main__":
    # Define the Perceptron instances for different gates
    and_gate = Perceptron(2)
    or_gate = Perceptron(2)
    not_gate = Perceptron(1)
    xor_gate = Perceptron(2)

    # Training data and labels for each gate
    training_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    
    # AND Gate
    and_labels = np.array([0, 0, 0, 1])
    and_gate.train(training_data, and_labels, epochs=1000)
    
    # OR Gate
    or_labels = np.array([0, 1, 1, 1])
    or_gate.train(training_data, or_labels, epochs=1000)
    
    # NOT Gate
    not_labels = np.array([1, 0])
    not_gate.train(np.array([[0], [1]]), not_labels, epochs=1000)
    
    # XOR Gate (Combining perceptrons for AND, OR, and NOT)
    def xor_gate(x1, x2):
        result = and_gate.predict([or_gate.predict([not_gate.predict([x1]), x2]), and_gate.predict([x1, not_gate.predict([x2])])])
        return result
    
    # Test the gates
    print("AND Gate:")
    print(and_gate.predict([0, 0]))
    print(and_gate.predict([0, 1]))
    print(and_gate.predict([1, 0]))
    print(and_gate.predict([1, 1]))
    
    print("OR Gate:")
    print(or_gate.predict([0, 0]))
    print(or_gate.predict([0, 1]))
    print(or_gate.predict([1, 0]))
    print(or_gate.predict([1, 1]))
    
    print("NOT Gate:")
    print(not_gate.predict([0]))
    print(not_gate.predict([1]))
    
    print("XOR Gate:")
    print(xor_gate(0, 0))
    print(xor_gate(0, 1))
    print(xor_gate(1, 0))
    print(xor_gate(1, 1))


This code defines a Perceptron class and demonstrates its use to create perceptrons for AND, OR, NOT, and XOR gates. The gates are trained using appropriate training data and labels, and then tested with various inputs."""





2. Implementing Perceptron Using Python:

Below is a Python code that implements a basic perceptron:


import numpy as np

class Perceptron:
    def __init__(self, num_inputs, learning_rate=0.1):
        # Initialize weights and bias
        self.weights = np.random.rand(num_inputs)
        self.bias = np.random.rand()
        self.learning_rate = learning_rate

    def predict(self, inputs):
        # Calculate the weighted sum of inputs
        weighted_sum = np.dot(inputs, self.weights) + self.bias
        # Apply the activation function (Step function)
        return 1 if weighted_sum > 0 else 0

    def train(self, training_data, labels, epochs):
        for _ in range(epochs):
            for inputs, label in zip(training_data, labels):
                prediction = self.predict(inputs)
                error = label - prediction
                # Update weights and bias
                self.weights += self.learning_rate * error * inputs
                self.bias += self.learning_rate * error

# Example usage for a basic Perceptron
if __name__ == "__main__":
    # Create a Perceptron with 2 input neurons
    perceptron = Perceptron(2)

    # Training data and labels
    training_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    labels = np.array([0, 0, 0, 1])

    # Train the Perceptron
    perceptron.train(training_data, labels, epochs=1000)

    # Test the trained Perceptron
    print(perceptron.predict([0, 0]))  # Expected output: 0
    print(perceptron.predict([0, 1]))  # Expected output: 0
    print(perceptron.predict([1, 0]))  # Expected output: 0
    print(perceptron.predict([1, 1]))  # Expected output: 1



This code defines a Perceptron class, initializes weights and bias, implements the prediction function, and provides a training method. It also includes an example of using the perceptron to perform a basic logical operation (in this case, the OR gate). You can modify the training data and labels to create perceptrons for different tasks or gates.