library(ISLR2)
library(e1071)
library(caret)
# Load the Khan dataset
data(Khan)
# Check dataset information
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
# Create a data frame for training
dat <- data.frame(
x = Khan$xtrain,
y = as.factor(Khan$ytrain)
)
# Train a linear SVM model
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
# Display the SVM model summary
summary(out)
# Create a data frame for testing
dat.te <- data.frame(
x = Khan$xtest,
y = as.factor(Khan$ytest)
)
# Make predictions on the test data
pred.te <- predict(out, newdata = dat.te)
# Create a confusion matrix to evaluate the predictions
confusion_matrix <- table(pred.te, dat.te$y)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
# Plot the SVM decision boundary and support vectors
plot(out, dat)
library(ISLR2)
library(e1071)
library(caret)
# Load the Khan dataset
data(Khan)
# Check dataset information
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
# Create a data frame for training
dat <- data.frame(
x = Khan$xtrain,
y = as.factor(Khan$ytrain)
)
# Train a linear SVM model
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
# Display the SVM model summary
summary(out)
# Create a data frame for testing
dat.te <- data.frame(
x = Khan$xtest,
y = as.factor(Khan$ytest)
)
# Make predictions on the test data
pred.te <- predict(out, newdata = dat.te)
# Create a confusion matrix to evaluate the predictions
confusion_matrix <- table(pred.te, dat.te$y)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
# Plot the SVM decision boundary and support vectors
plot.svm(out, dat)
library(ISLR2)
library(e1071)
library(caret)
library(ggplot2)
# Load the Khan dataset
data(Khan)
# Check dataset information
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
# Create a data frame for training
dat <- data.frame(
x = Khan$xtrain,
y = as.factor(Khan$ytrain)
)
# Train a linear SVM model
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
# Display the SVM model summary
summary(out)
# Create a data frame for testing
dat.te <- data.frame(
x = Khan$xtest,
y = as.factor(Khan$ytest)
)
# Make predictions on the test data
pred.te <- predict(out, newdata = dat.te)
# Create a confusion matrix to evaluate the predictions
confusion_matrix <- table(pred.te, dat.te$y)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
# Create a scatterplot to visualize the decision boundary and support vectors
ggplot(dat, aes(x = X1, y = X2, color = factor(y))) +
geom_point() +
geom_contour(data = expand.grid(X1 = seq(min(dat$X1), max(dat$X1), length = 100),
X2 = seq(min(dat$X2), max(dat$X2), length = 100)),
aes(x = X1, y = X2, z = as.numeric(predict(out, newdata = data.frame(X1, X2)))),
bins = 10, color = "black") +
geom_point(data = dat[svIndices(out), ], shape = 1, size = 3) +
labs(title = "SVM Decision Boundary and Support Vectors") +
theme_minimal()
library(ISLR2)
library(ggplot2)
# Load the Khan dataset
data(Khan)
# Check dataset information
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
# Create a data frame for training
dat <- data.frame(
x = Khan$xtrain,
y = as.factor(Khan$ytrain)
)
# Train a linear SVM model
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
# Display the SVM model summary
summary(out)
# Create a data frame for testing
dat.te <- data.frame(
x = Khan$xtest,
y = as.factor(Khan$ytest)
)
# Make predictions on the test data
pred.te <- predict(out, newdata = dat.te)
# Create a confusion matrix to evaluate the predictions
confusion_matrix <- table(pred.te, dat.te$y)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
# Create a scatterplot to visualize the SVM model's predictions
ggplot(dat.te, aes(x = X1, y = X2, color = factor(pred.te))) +
geom_point() +
labs(title = "SVM Model Predictions") +
theme_minimal()
library(ISLR2)
library(caret)
# Load the Khan dataset
data(Khan)
# Check dataset information
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
# Create a data frame for training
dat <- data.frame(
x = Khan$xtrain,
y = as.factor(Khan$ytrain)
)
# Train a linear SVM model
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
# Display the SVM model summary
summary(out)
# Create a data frame for testing
dat.te <- data.frame(
x = Khan$xtest,
y = as.factor(Khan$ytest)
)
# Make predictions on the test data
pred.te <- predict(out, newdata = dat.te)
# Create a confusion matrix to evaluate the predictions
confusion_matrix <- table(pred.te, dat.te$y)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
# Create a confusion matrix plot
confusionMatrixPlot(confusion_matrix, colors = c("red", "green"))
# Load the required libraries
library(ISLR2)
library(caret)
library(yardstick)
# Load the required libraries
library(ISLR2)
library(caret)
library(yardstick)
# Load the Khan dataset
data(Khan)
# Check dataset information
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
# Create a data frame for training
dat <- data.frame(
x = Khan$xtrain,
y = as.factor(Khan$ytrain)
)
# Train a linear SVM model
out <- svm(y ~ ., data = dat, kernel = "linear", cost = 10)
# Display the SVM model summary
summary(out)
# Create a data frame for testing
dat.te <- data.frame(
x = Khan$xtest,
y = as.factor(Khan$ytest)
)
# Make predictions on the test data
pred.te <- predict(out, newdata = dat.te)
# Create a confusion matrix to evaluate the predictions
confusion_matrix <- table(pred.te, dat.te$y)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
# Create a confusion matrix plot
plotConfusionMatrix(confusion_matrix, theme = "tight")
